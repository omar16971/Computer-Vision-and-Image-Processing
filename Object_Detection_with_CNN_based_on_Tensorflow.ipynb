{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbea2df3-43ad-4b65-8a73-977c5e52acc5",
   "metadata": {},
   "source": [
    "<h2>Object Detection with Convolution Neural Network (CNN) based on Tensorflow</h2>\n",
    "<h3>Application: Mask Detection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06e9cd2-de4b-436b-b886-8b4fa6408b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lvis in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (0.5.3)\n",
      "Requirement already satisfied: tf_slim in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tf_slim) (2.1.0)\n",
      "Requirement already satisfied: tensorflowjs in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (1.4.0)\n",
      "Collecting h5py==2.8.0 (from tensorflowjs)\n",
      "  Using cached h5py-2.8.0.tar.gz (274 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy==1.16.4 (from tensorflowjs)\n",
      "  Using cached numpy-1.16.4.zip (5.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting six==1.11.0 (from tensorflowjs)\n",
      "  Using cached six-1.11.0-py2.py3-none-any.whl (10 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflowjs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflowjs\n",
      "  Downloading tensorflowjs-4.17.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting flax>=0.7.2 (from tensorflowjs)\n",
      "  Downloading flax-0.8.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting importlib_resources>=5.9.0 (from tensorflowjs)\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jax>=0.4.13 (from tensorflowjs)\n",
      "  Downloading jax-0.4.24-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jaxlib>=0.4.13 (from tensorflowjs)\n",
      "  Downloading jaxlib-0.4.24-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: tensorflow<3,>=2.13.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflowjs) (2.15.0)\n",
      "Collecting tensorflow-decision-forests>=1.5.0 (from tensorflowjs)\n",
      "  Downloading tensorflow_decision_forests-1.8.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: six<2,>=1.16.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflowjs) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.14.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflowjs) (0.16.1)\n",
      "Requirement already satisfied: packaging~=23.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflowjs) (23.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from flax>=0.7.2->tensorflowjs) (1.26.3)\n",
      "Collecting msgpack (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading msgpack-1.0.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting optax (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading optax-0.1.9-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting orbax-checkpoint (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading orbax_checkpoint-0.5.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorstore (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading tensorstore-0.1.53-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1 (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from flax>=0.7.2->tensorflowjs) (4.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from flax>=0.7.2->tensorflowjs) (6.0.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from jax>=0.4.13->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from jax>=0.4.13->tensorflowjs) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from jax>=0.4.13->tensorflowjs) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (16.0.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (4.25.2)\n",
      "Requirement already satisfied: setuptools in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (68.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.4.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\n",
      "Requirement already satisfied: pandas in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.0)\n",
      "Requirement already satisfied: wheel in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.41.2)\n",
      "Collecting wurlitzer (from tensorflow-decision-forests>=1.5.0->tensorflowjs)\n",
      "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow-hub>=0.14.0->tensorflowjs) (2.15.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1->flax>=0.7.2->tensorflowjs)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.17.2)\n",
      "Collecting chex>=0.1.7 (from optax->flax>=0.7.2->tensorflowjs)\n",
      "  Downloading chex-0.1.85-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting etils[epath,epy] (from orbax-checkpoint->flax>=0.7.2->tensorflowjs)\n",
      "  Downloading etils-1.6.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: nest_asyncio in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\n",
      "INFO: pip is looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorstore (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading tensorstore-0.1.52-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.51-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting orbax-checkpoint (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading orbax_checkpoint-0.5.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorstore (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading tensorstore-0.1.50-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "  Downloading tensorstore-0.1.49-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tensorstore-0.1.48-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "  Downloading tensorstore-0.1.47-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "  Downloading tensorstore-0.1.46-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "  Downloading tensorstore-0.1.45-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting orbax-checkpoint (from flax>=0.7.2->tensorflowjs)\n",
      "  Downloading orbax_checkpoint-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.7-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.6-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.5-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Downloading orbax_checkpoint-0.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2023.4)\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.7->optax->flax>=0.7.2->tensorflowjs)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.1)\n",
      "Requirement already satisfied: fsspec in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2023.12.2)\n",
      "Collecting zipp (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs)\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (2.1.4)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow<3,>=2.13.0->tensorflowjs) (3.2.2)\n",
      "Downloading tensorflowjs-4.17.0-py3-none-any.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m73.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading flax-0.8.1-py3-none-any.whl (677 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.6/677.6 kB\u001b[0m \u001b[31m79.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Downloading jax-0.4.24-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m283.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.24-cp311-cp311-macosx_11_0_arm64.whl (68.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 MB\u001b[0m \u001b[31m76.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:29\u001b[0mm\n",
      "\u001b[?25hDownloading tensorflow_decision_forests-1.8.1-cp311-cp311-macosx_12_0_arm64.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m239.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m71.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.0.7-cp311-cp311-macosx_11_0_arm64.whl (231 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m36.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading optax-0.1.9-py3-none-any.whl (197 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.2/197.2 kB\u001b[0m \u001b[31m78.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorstore-0.1.45-cp311-cp311-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m308.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading orbax_checkpoint-0.4.4-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m497.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chex-0.1.85-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m636.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m668.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading etils-1.6.0-py3-none-any.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.9/144.9 kB\u001b[0m \u001b[31m414.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: zipp, wurlitzer, toolz, tensorstore, msgpack, mdurl, importlib_resources, etils, markdown-it-py, jaxlib, jax, rich, chex, orbax-checkpoint, optax, flax, tensorflow-decision-forests, tensorflowjs\n",
      "  Attempting uninstall: tensorflowjs\n",
      "    Found existing installation: tensorflowjs 1.4.0\n",
      "    Uninstalling tensorflowjs-1.4.0:\n",
      "      Successfully uninstalled tensorflowjs-1.4.0\n",
      "Successfully installed chex-0.1.85 etils-1.6.0 flax-0.8.1 importlib_resources-6.1.1 jax-0.4.24 jaxlib-0.4.24 markdown-it-py-3.0.0 mdurl-0.1.2 msgpack-1.0.7 optax-0.1.9 orbax-checkpoint-0.4.4 rich-13.7.0 tensorflow-decision-forests-1.8.1 tensorflowjs-4.17.0 tensorstore-0.1.45 toolz-0.12.1 wurlitzer-3.0.3 zipp-3.17.0\n",
      "Requirement already satisfied: tensorflow_hub in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow_hub) (1.26.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow_hub) (4.25.2)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /Users/omaraffifi/miniconda3/lib/python3.11/site-packages (from tensorflow_hub) (2.15.0)\n"
     ]
    }
   ],
   "source": [
    "# import the libraries for OS and Cloud\n",
    "\n",
    "!pip install --no-deps lvis\n",
    "!pip install tf_slim\n",
    "!pip install tensorflowjs\n",
    "#!pip install tensorflow==1.15.2\n",
    "!pip install tensorflow_hub\n",
    "\n",
    "from IPython.display import display, Javascript, Image\n",
    "import re\n",
    "import zipfile\n",
    "from base64 import b64decode\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import io\n",
    "import random\n",
    "\n",
    "import tarfile\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n",
    "import six.moves.urllib as urllib\n",
    "import PIL.Image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b6530f-99f8-4659-9b41-4ef09dd2d42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# import libraries for tensorflow\n",
    "\n",
    "%%capture\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util, label_map_util, config_util\n",
    "from object_detection.utils.label_map_util import get_label_map_dict\n",
    "from skillsnetwork import cvstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd2a846e-a8f4-431f-97bc-73c1b6758583",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/CV0101/content/data/content-latest.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/CV0101/content/data/tfrecord.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent-latest.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m     10\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/zipfile.py:1302\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1302\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/zipfile.py:1369\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "# download files to buid the model\n",
    "import os\n",
    "if os.path.exists(\"content-latest.zip\"):\n",
    "    pass\n",
    "else:\n",
    "    !wget https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/CV0101/content/data/content-latest.zip\n",
    "    !wget https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/CV0101/content/data/tfrecord.py\n",
    "    \n",
    "with zipfile.ZipFile('content-latest.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aba2d5-a509-4b89-9665-0d17a43e029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the CV Studio Client and download the images\n",
    "# Initialize the CV Studio Client\n",
    "cvstudioClient = cvstudio.CVStudio()\n",
    "\n",
    "# Download All Images\n",
    "cvstudioClient.downloadAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fefef74-4e6f-4ab1-9cf1-e5455ebb9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the annotations from CV Studio\n",
    "annotations = cvstudioClient.get_annotations()\n",
    "labels = annotations['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8806a-f438-40b6-aba1-f7109bc2be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the folder path\n",
    "CHECKPOINT_PATH = os.path.join(os.getcwd(),'content/checkpoint')\n",
    "OUTPUT_PATH = os.path.join(os.getcwd(),'content/output')\n",
    "EXPORTED_PATH = os.path.join(os.getcwd(),'content/exported')\n",
    "DATA_PATH = os.path.join(os.getcwd(),'content/data')\n",
    "CONFIG_PATH = os.path.join(os.getcwd(),'content/config')\n",
    "LABEL_MAP_PATH = os.path.join(DATA_PATH, 'label_map.pbtxt')\n",
    "TRAIN_RECORD_PATH = os.path.join(DATA_PATH, 'train.record')\n",
    "VAL_RECORD_PATH = os.path.join(DATA_PATH, 'val.record')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f500d-e2fe-4b0b-8017-bf44574b6c37",
   "metadata": {},
   "source": [
    "## Image pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cd755-8330-48e4-a515-9752eea81dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give an id number for each annotated image as a label map starting from 1\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "with open(LABEL_MAP_PATH, 'w') as f:\n",
    "    for idx, label in enumerate(labels):\n",
    "        f.write('item {\\n')\n",
    "        f.write(\"\\tname: '{}'\\n\".format(label))\n",
    "        f.write('\\tid: {}\\n'.format(idx + 1))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be05be-6494-4f66-b093-7f2adff30dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation\n",
    "from tfrecord import create_tf_record, displaydetectedobject\n",
    "image_files = [image for image in annotations[\"annotations\"].keys()]\n",
    "\n",
    "label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(image_files)\n",
    "num_train = int(0.7 * len(image_files))\n",
    "train_examples = image_files[:num_train]\n",
    "val_examples = image_files[num_train:]\n",
    "\n",
    "create_tf_record(train_examples, annotations[\"annotations\"], label_map, os.path.join(os.getcwd(),'images'), TRAIN_RECORD_PATH)\n",
    "create_tf_record(val_examples, annotations[\"annotations\"], label_map, os.path.join(os.getcwd(),'images'), VAL_RECORD_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382322ca-34e5-4aaa-aa74-9f6b5674b173",
   "metadata": {},
   "source": [
    "## Selecting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb0a1b-4b1b-41df-8743-31c1dda3a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the model \"MobileNet V1\", the model is pre-trained with a checkpoint that we will strart this notebook from\n",
    "MODEL_TYPE = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync_2018_07_18'\n",
    "CONFIG_TYPE = 'ssd_mobilenet_v1_quantized_300x300_coco14_sync'\n",
    "download_base = 'http://download.tensorflow.org/models/object_detection/'\n",
    "model = MODEL_TYPE + '.tar.gz'\n",
    "tmp = '/resources/checkpoint.tar.gz'\n",
    "\n",
    "if not (os.path.exists(CHECKPOINT_PATH)):\n",
    "    # Download the checkpoint\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(download_base + model, tmp)\n",
    "\n",
    "    # Extract all the `model.ckpt` files.\n",
    "    with tarfile.open(tmp) as tar:\n",
    "        for member in tar.getmembers():\n",
    "            member.name = os.path.basename(member.name)\n",
    "            if 'model.ckpt' in member.name:\n",
    "                tar.extract(member, path=CHECKPOINT_PATH)\n",
    "            if 'pipeline.config' in member.name:\n",
    "                tar.extract(member, path=CONFIG_PATH)\n",
    "\n",
    "    os.remove(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890763a7-c09d-4740-90cb-a12a0513de51",
   "metadata": {},
   "source": [
    "## Building the model training pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ab8503-1df5-432c-bdc4-16df5ac253a4",
   "metadata": {},
   "source": [
    "This is the the last stage before we start training the model. We need to inject our pipeline with the label map and TFRecord that we created previosuly in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e215b5-cea2-4664-922a-a861aba2802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline_skeleton = 'content/models/research/object_detection/samples/configs/' + CONFIG_TYPE + '.config'\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_skeleton)\n",
    "\n",
    "label_map = label_map_util.get_label_map_dict(LABEL_MAP_PATH)\n",
    "num_classes = len(label_map.keys())\n",
    "meta_arch = configs[\"model\"].WhichOneof(\"model\")\n",
    "\n",
    "override_dict = {\n",
    "  'model.{}.num_classes'.format(meta_arch): num_classes,\n",
    "  'train_config.batch_size': 6,\n",
    "  'train_input_path': TRAIN_RECORD_PATH,\n",
    "  'eval_input_path': VAL_RECORD_PATH,\n",
    "  'train_config.fine_tune_checkpoint': os.path.join(CHECKPOINT_PATH, 'model.ckpt'),\n",
    "  'label_map_path': LABEL_MAP_PATH\n",
    "}\n",
    "\n",
    "configs = config_util.merge_external_params_with_configs(configs, kwargs_dict=override_dict)\n",
    "pipeline_config = config_util.create_pipeline_proto_from_configs(configs)\n",
    "config_util.save_pipeline_config(pipeline_config, DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b81d1b-dde6-4547-9d58-592778c03d40",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039c592-c9ce-410c-970a-a04a2752fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to train MobileNet\n",
    "paths = [\n",
    "    f'home/jupyterlab/conda/envs/python/lib/python3.6',\n",
    "    f'content/models/research',\n",
    "    f'content/models/research/slim'\n",
    "]\n",
    "os.environ['PYTHONPATH'] = ':'.join(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77981ff-c6fd-4a2d-beaa-75170f123a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "epochs = 40\n",
    "start_datetime = datetime.now()\n",
    "!python -m object_detection.model_main \\\n",
    "    --pipeline_config_path=$DATA_PATH/pipeline.config \\\n",
    "    --num_train_steps=$epochs \\\n",
    "    --num_eval_steps=100\n",
    "\n",
    "regex = re.compile(r\"model\\.ckpt-([0-9]+)\\.index\")\n",
    "numbers = [int(regex.search(f).group(1)) for f in os.listdir(OUTPUT_PATH) if regex.search(f)]\n",
    "TRAINED_CHECKPOINT_PREFIX = os.path.join(OUTPUT_PATH, 'model.ckpt-{}'.format(max(numbers)))\n",
    "\n",
    "!python3 -m object_detection.export_inference_graph \\\n",
    "  --pipeline_config_path=$DATA_PATH/pipeline.config \\\n",
    "  --trained_checkpoint_prefix=$TRAINED_CHECKPOINT_PREFIX \\\n",
    "  --output_directory=$EXPORTED_PATH\n",
    "end_datetime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc518d65-fd5d-43b4-8280-1b7cef9f1541",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43edfd5-ac38-43ae-85c1-dd6cf504697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Here you can specify your own image \n",
    "URL = 'https://cdn.cliqueinc.com/posts/289533/kamala-harris-face-mask-289533-1602269219518-square.700x0c.jpg' \n",
    "\n",
    "with urllib.request.urlopen(URL) as url:\n",
    "    with open('test.jpg', 'wb') as f:\n",
    "        f.write(url.read())\n",
    "image = Image.open('test.jpg')\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d292e2-34fe-42cc-8f1b-f6b788260865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "n,img,accuracy=displaydetectedobject(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376cc75-3ac7-41af-b03d-f6510f79aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'epochs': epochs\n",
    "}\n",
    "\n",
    "result = cvstudioClient.report(started=start_datetime, completed=end_datetime, parameters=parameters, accuracy= round(float(accuracy),2)*100)\n",
    "\n",
    "if result.ok:\n",
    "    print('Congratulations your results have been reported back to CV Studio!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07b958-71da-4c9f-adad-9d955ac70388",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1c6c1-af3f-4284-9526-9995e9bfc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!tensorflowjs_converter \\\n",
    "  --input_format=tf_frozen_model \\\n",
    "  --output_format=tfjs_graph_model \\\n",
    "  --output_node_names='Postprocessor/ExpandDims_1,Postprocessor/Slice' \\\n",
    "  --quantization_bytes=1 \\\n",
    "  --skip_op_check \\\n",
    "  $EXPORTED_PATH/frozen_inference_graph.pb \\\n",
    "  .\n",
    "import json\n",
    "\n",
    "from object_detection.utils.label_map_util import get_label_map_dict\n",
    "\n",
    "label_map = get_label_map_dict(LABEL_MAP_PATH)\n",
    "label_array = [k for k in sorted(label_map, key=label_map.get)]\n",
    "\n",
    "with open(os.path.join('', 'labels.json'), 'w') as f:\n",
    "    json.dump(label_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c53e0d-2799-4c2d-8802-a7129f464bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd model_web \n",
    "with ZipFile('model_web.zip','w') as zip:\n",
    "    zip.write('group1-shard1of2.bin')\n",
    "    zip.write('group1-shard2of2.bin')\n",
    "    zip.write('model.json')\n",
    "    zip.write('labels.json')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552bba42-99f5-4615-83de-f3c14ed755b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download All Images\n",
    "cvstudioClient.uploadModel('model_web.zip', {'epochs': epochs })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6b6e7-08d7-48ed-8c2a-325c80e6e9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
